{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-class FSA\n",
    "\n",
    "1. Implement the FSA variable selection method with linear models for multi-class\n",
    "classification with the Vapnik los\n",
    "$L(\\bf{u}, y) = \\Sigma_{k\\not=y} l(u_y-u_k)$\n",
    "\n",
    "where $l(u)$ is the logistic loss described in class. Use the parameters $\\lambda = 0.0001, \\mu =\n",
    "100, N^{iter} = 500$.\n",
    "Take special care to normalize each column of the $X$ matrix to have zero mean\n",
    "and variance $1$ and to use for normalizing the test set the same mean and standard\n",
    "deviation that you used for normalizing the training set.\n",
    "Assuming that the coefficient vector is a $p \\times c$ matrix $W$, where $p$ is the number of\n",
    "features and c is the number of classes, use the norm $||\\bf{w}_j||, j = 1, ..., p$ of each row as\n",
    "the criterion to select the variables in FSA."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 650,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Normalization function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "outputs": [],
   "source": [
    "def normalize(train, *args):\n",
    "    mean = np.average(train, axis=0)\n",
    "    standard_deviation = np.std(train, axis=0)\n",
    "    columns = train, *args\n",
    "    return tuple(np.divide(column-mean, standard_deviation, where=standard_deviation!=0)\n",
    "                 for column in columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[ 1.6504898 ,  1.37065618,  1.24035744, ...,  1.04773951,\n          0.83669871,  0.23370924],\n        [ 1.06432744,  0.79853645,  0.40053984, ...,  0.69624747,\n          0.29644556, -0.18971944],\n        [ 1.06432744,  0.79853645,  0.16059195, ...,  0.69624747,\n          0.29644556, -0.18971944],\n        ...,\n        [-0.10799728, -0.38971222,  0.52051378, ...,  0.74018398,\n          0.29644556,  0.12785207],\n        [ 0.11181361,  0.1383983 ,  0.52051378, ...,  0.34475544,\n          0.29644556,  0.12785207],\n        [ 0.11181361,  0.31443514,  0.04061801, ...,  0.34475544,\n          0.05633305, -0.08386227]]),\n array([[0., 1., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        ...,\n        [0., 0., 1., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 0., 1., 0., 0.]]),\n array([[ 0.77124626,  0.79853645,  0.16059195, ...,  1.04773951,\n          0.83669871,  0.23370924],\n        [ 0.47816508,  0.79853645,  0.16059195, ...,  0.87199349,\n          0.29644556,  0.0219949 ],\n        [ 0.77124626,  0.62249961,  0.40053984, ...,  0.52050146,\n         -0.18377946, -0.40143378],\n        ...,\n        [-0.98724082, -0.69777669, -0.49926473, ..., -0.0067366 ,\n         -0.42389197, -0.45436237],\n        [-0.98724082, -0.69777669, -0.73921262, ..., -0.0067366 ,\n         -0.42389197, -0.66607671],\n        [-0.69415964, -0.56574906, -0.49926473, ..., -0.18248262,\n          0.53655807,  0.49835217]]),\n array([[0., 1., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        ...,\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 1., 0.]]))"
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data():\n",
    "    path = \"data/satimage/\"\n",
    "\n",
    "    train_x = np.loadtxt(path + \"X.dat\")\n",
    "    train_y_temp = np.loadtxt(path + \"Y.dat\", dtype=np.int)\n",
    "    test_x = np.loadtxt(path + \"Xtest.dat\")\n",
    "    test_y_temp = np.loadtxt(path + \"Ytest.dat\", dtype=np.int)\n",
    "\n",
    "    train_x, test_x = normalize(train_x, test_x)\n",
    "\n",
    "    train_y = np.zeros((train_y_temp.size,np.max(train_y_temp)))\n",
    "    train_y[np.arange(train_y_temp.size),train_y_temp-1] = 1\n",
    "\n",
    "    test_y = np.zeros((test_y_temp.size,train_y.shape[1]))\n",
    "    test_y[np.arange(test_y_temp.size),test_y_temp-1] = 1\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "get_data()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculate the next iteration's weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "outputs": [],
   "source": [
    "def update_weights(w, x, y):\n",
    "    learning_rate = 1/x.shape[0]\n",
    "    learning_rate = .05\n",
    "    return w + learning_rate * L(w, x, y)\n",
    "\n",
    "def L(w, x, y):\n",
    "    \"\"\"\n",
    "    Gradient of logistic loss function with sparsity-inducing penalty\n",
    "    \"\"\"\n",
    "    s = 0.0001\n",
    "    w = torch.from_numpy(w)\n",
    "    x = torch.from_numpy(x)\n",
    "    y = torch.from_numpy(y)\n",
    "\n",
    "    w.requires_grad = True\n",
    "    y_predicted = torch.matmul(x,w)\n",
    "    difference = y - y_predicted\n",
    "    difference[y==1]=0\n",
    "    #print(\"before\", torch.nansum(difference))\n",
    "    #difference+= .0001\n",
    "    #print(torch.log(torch.exp(difference)+1) - torch.log(torch.exp(difference)))\n",
    "    print(torch.min(1+torch.exp(-difference)))\n",
    "    loss = torch.log(1 + torch.exp(-difference))\n",
    "    #print(loss)\n",
    "    #loss = torch.log(torch.exp(difference)+1) - torch.log(torch.exp(difference))\n",
    "    #print(\"after\", torch.nansum(loss))\n",
    "    loss = torch.sum(loss)\n",
    "    #print(y_predicted)\n",
    "    loss.backward()\n",
    "    #print(loss.detach().numpy())\n",
    "    gradient = w.grad + 2 * s * 2\n",
    "    return gradient.numpy()\n",
    "\n",
    "    #return x.T.dot(y-(1/(1+np.exp(-np.dot(x,w))))) + 2 * s * w\n",
    "\n",
    "def predict(X,w):\n",
    "    \"\"\"\n",
    "    Predictor function for logistic regression\n",
    "    \"\"\"\n",
    "    z = X @ w\n",
    "    z /= np.sum(z,axis=1).reshape(-1,1)\n",
    "    result = np.zeros_like(z)\n",
    "    result[np.arange(z.shape[0]), np.argmax(z, axis=1)] = 1\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculate the number of parameters to keep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "outputs": [],
   "source": [
    "def calc_schedule(num_params, k, num_iterations):\n",
    "    mu = 30\n",
    "    return [round(k+(num_params-k)*max(0,(num_iterations-2*i)/(2*i*mu+num_iterations)))\n",
    "            for i in range(1,num_iterations+1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Eliminate Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "outputs": [],
   "source": [
    "def eliminate_parameters(parameters_to_keep, w, x_train, x_test):\n",
    "    \"\"\"\n",
    "    Eliminates the parameters which have the smallest weights so that parameters_to_keep parameter remain\n",
    "    \"\"\"\n",
    "    # list of indexes that would sort the array\n",
    "    sorted_indexes = np.argsort(np.linalg.norm(w, axis=1))\n",
    "    # index thresholds used to eliminate insignificant parameters\n",
    "    threshold = w.shape[0] - parameters_to_keep\n",
    "    # delete indexes smaller than threshold\n",
    "    w = np.delete(w, sorted_indexes[sorted_indexes < threshold], axis=0)\n",
    "    x_train = np.delete(x_train, sorted_indexes[sorted_indexes < threshold], axis=1)\n",
    "    x_test = np.delete(x_test, sorted_indexes[sorted_indexes < threshold], axis=1)\n",
    "    #print('after',w)\n",
    "    return w, x_train, x_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train logistic regression model using FSA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oscar\\anaconda3\\envs\\tensor_environemnt\\lib\\site-packages\\ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(1., dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<MinBackward1>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_fsa(x_train, y_train, x_test, y_test, k):\n",
    "    iterations = 500\n",
    "    x_train, x_test = normalize(x_train, x_test)\n",
    "    # append column of ones for the intercept\n",
    "    x_train = np.hstack((np.ones((x_train.shape[0], 1)), x_train))\n",
    "    x_test = np.hstack((np.ones((x_test.shape[0], 1)), x_test))\n",
    "    # make sure data is binary 0,1 rather than -1,1\n",
    "\n",
    "    w = np.zeros((x_train.shape[1], y_train.shape[1])) # initializing weights to 0\n",
    "    schedule = calc_schedule(w.shape[0], k, iterations)\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_scores.append(1 - accuracy_score(y_train, predict(x_train, w)))\n",
    "    test_scores.append(1 - accuracy_score(y_test, predict(x_test, w)))\n",
    "    for parameters_to_keep in schedule:\n",
    "        if parameters_to_keep == 0:\n",
    "            break\n",
    "        w = update_weights(w, x_train, y_train)\n",
    "        w, x_train, x_test = eliminate_parameters(parameters_to_keep, w, x_train, x_test)\n",
    "        train_scores.append(1 - accuracy_score(y_train, predict(x_train, w)))\n",
    "        test_scores.append(1 - accuracy_score(y_test, predict(x_test, w)))\n",
    "    number_of_features = w.shape[0]\n",
    "    return test_scores, train_scores, number_of_features\n",
    "\n",
    "train_x, train_y, test_x, test_y = get_data()\n",
    "k =  5\n",
    "train_fsa(train_x, train_y, test_x, test_y, k)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "a) Using the satimage data, train a multi-class FSA classifier on the training set,\n",
    "starting with $\\beta(0) = 0$ to select $k \\in \\{5, 9, 18, 27, 36\\}$ features. For each $k$ find\n",
    "an appropriate learning rate $\\eta$ to obtain a small final loss value on the training\n",
    "set. Plot the training loss vs iteration number for $k = 27$. (5 points)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "b) Report in a table the misclassification errors on the training and test set for the\n",
    "models obtained for all these $k$. Plot the misclassification error on the training\n",
    "and test set vs $k$. (1 point)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "c) Repeat points a) and b) using the cross-entropy loss function:\n",
    "$L(\\bf{u}, y) = âˆ’u_y + \\ln(\\Sigma_{k=1}^C \\exp(u_k))$\n",
    "adding the misclassification errors to the table from b). (4 points).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Oscar Kosar-Kosarewicz"
   },
   {
    "name": "Nicholas Phillips"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}