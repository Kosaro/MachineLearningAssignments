{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Logistic Regression Assignment\n",
    "Implement the Logistic Regression learning by gradient ascent as described in class.\n",
    "Before using logistic regression, be sure to normalize the variables of the training set\n",
    "to have zero mean and standard deviation 1, and to do the exact same transformation to\n",
    "the test set, using the mean and standard deviation of the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Utility functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def get_gisette():\n",
    "    path = \"data/gisette/\"   \n",
    "    \n",
    "    train_x = np.loadtxt(path+\"gisette_train.data\")\n",
    "    train_y = np.loadtxt(path+\"gisette_train.labels\")\n",
    "    \n",
    "    valid_x = np.loadtxt(path+\"gisette_valid.data\")\n",
    "    valid_y = np.loadtxt(path+\"gisette_valid.labels\")\n",
    "    \n",
    "    test_x = np.loadtxt(path+\"gisette_test.data\")\n",
    "\n",
    "    return train_x, train_y, valid_x, valid_y, test_x\n",
    "\n",
    "\n",
    "def get_hill_valley():\n",
    "    path = \"data/hill-valley/\"   \n",
    "    \n",
    "    train_x = np.loadtxt(path+\"X.dat\")\n",
    "    train_y = np.loadtxt(path+\"Y.dat\")\n",
    "    \n",
    "    test_x = np.loadtxt(path+\"Xtest.dat\")\n",
    "    test_y = np.loadtxt(path+\"Ytest.dat\")\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def get_dexter():\n",
    "    path = \"data/dexter/\"   \n",
    "    \n",
    "    def parse_X(file_path):\n",
    "        def gen():\n",
    "            with open(file_path) as f:\n",
    "                for line in f:\n",
    "                    dict = {}\n",
    "                    for pair in line.split(\" \"):\n",
    "                        if \":\" in pair:\n",
    "                            key, value = pair.split(\":\")\n",
    "                            dict[key] = value\n",
    "                    yield dict\n",
    "        df = pd.DataFrame(gen())\n",
    "        df.fillna(0, inplace=True)\n",
    "        return csr_matrix(df.values.astype(\"int\"))\n",
    "    \n",
    "    train_x = parse_X(path+\"dexter_train.data\")\n",
    "    train_y = np.loadtxt(path+\"dexter_train.labels\")\n",
    "    \n",
    "    valid_x = parse_X(path+\"dexter_valid.data\")\n",
    "    valid_y = np.loadtxt(path+\"dexter_valid.labels\")\n",
    "    \n",
    "    test_x = parse_X(path+\"dexter_test.data\")\n",
    "    \n",
    "    return train_x, train_y, valid_x, valid_y, test_x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def normalize(train, *args):\n",
    "    mean = np.average(train, axis=0)\n",
    "    standard_deviation = np.std(train, axis=0)\n",
    "    columns = train, *args\n",
    "    return tuple(np.divide(column-mean, standard_deviation, where=standard_deviation!=0)\n",
    "                 for column in columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\okosa\\pycharmprojects\\machinelearningassignments\\venv\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: overflow encountered in exp\n",
      "c:\\users\\okosa\\pycharmprojects\\machinelearningassignments\\venv\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: overflow encountered in exp\n",
      "c:\\users\\okosa\\pycharmprojects\\machinelearningassignments\\venv\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-66-592a6800bb5c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     24\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m \u001B[0mlogistic_regression\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalid_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalid_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-66-592a6800bb5c>\u001B[0m in \u001B[0;36mlogistic_regression\u001B[1;34m(x, train_y, test_x, test_y)\u001B[0m\n\u001B[0;32m     10\u001B[0m         \u001B[0mw\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mw\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlearning_rate\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mlmb\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mw\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlearning_rate\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mlog_likelihood_derivative\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0mpredicted_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mround\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m         \u001B[0mscores\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maccuracy_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpredicted_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0miterations\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscores\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\okosa\\pycharmprojects\\machinelearningassignments\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     70\u001B[0m                           FutureWarning)\n\u001B[0;32m     71\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     73\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\okosa\\pycharmprojects\\machinelearningassignments\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001B[0m in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    185\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    186\u001B[0m     \u001B[1;31m# Compute accuracy for each possible representation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 187\u001B[1;33m     \u001B[0my_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    188\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    189\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0my_type\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'multilabel'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\okosa\\pycharmprojects\\machinelearningassignments\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     81\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m     \u001B[0mtype_true\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 83\u001B[1;33m     \u001B[0mtype_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     84\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m     \u001B[0my_type\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mtype_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtype_pred\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\okosa\\pycharmprojects\\machinelearningassignments\\venv\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001B[0m in \u001B[0;36mtype_of_target\u001B[1;34m(y)\u001B[0m\n\u001B[0;32m    285\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'f'\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0many\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    286\u001B[0m         \u001B[1;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 287\u001B[1;33m         \u001B[0m_assert_all_finite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    288\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;34m'continuous'\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0msuffix\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    289\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\okosa\\pycharmprojects\\machinelearningassignments\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype)\u001B[0m\n\u001B[0;32m     97\u001B[0m                     \u001B[0mmsg_err\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m                     (type_err,\n\u001B[1;32m---> 99\u001B[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001B[0m\u001B[0;32m    100\u001B[0m             )\n\u001B[0;32m    101\u001B[0m     \u001B[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "def logistic_regression(x, train_y, test_x, test_y):\n",
    "    x = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "    #iterations = 300\n",
    "    iterations = 100\n",
    "    lmb = 0.0001\n",
    "    learning_rate = .01\n",
    "    w = np.zeros(x.shape[1])\n",
    "    scores = []\n",
    "    for _ in range(iterations):\n",
    "        w = w - learning_rate * lmb * w - learning_rate / x.shape[0] * log_likelihood_derivative(w, x, train_y)\n",
    "        predicted_y = np.round(predict(x, w))\n",
    "        scores.append(accuracy_score(train_y, predicted_y))\n",
    "    plt.plot(range(1,iterations + 1), scores)\n",
    "    plt.show()\n",
    "\n",
    "def log_likelihood_derivative(w, x, y):\n",
    "    y_hat = x.dot(w)\n",
    "    result = ((y - np.exp(y_hat)) / (1 + np.exp(y_hat)))\n",
    "    result = np.sum(x.T*result, axis=1)\n",
    "    return result\n",
    "\n",
    "def predict(x, w):\n",
    "    y = 1/(1 + np.exp(x.dot(w)))\n",
    "    return y\n",
    "\n",
    "#logistic_regression(train_x, train_y, valid_x, valid_y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gisette"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "train_x, train_y, valid_x, valid_y, test_x = get_gisette()\n",
    "train_x, valid_x, test_x = normalize(train_x, valid_x, test_x)\n",
    "train_y[train_y==-1] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.00000000e-03  1.51994153e-05  1.86458532e-05 ...  4.88508565e-04\n",
      " -2.52076466e-07  1.03010236e-03]\n",
      "[ 9.34335334e-03  4.39183292e-05  4.99099366e-05 ...  1.07238783e-03\n",
      " -3.35037101e-06  2.26041294e-03]\n",
      "[ 1.29648766e-02  8.69039185e-05  9.63795628e-05 ...  1.76319022e-03\n",
      " -1.13986163e-05  3.70659623e-03]\n",
      "[ 1.59023179e-02  1.41067166e-04  1.57649405e-04 ...  2.55664359e-03\n",
      " -2.37687093e-05  5.34629826e-03]\n",
      "[ 1.82972080e-02  1.99271725e-04  2.30143339e-04 ...  3.43354822e-03\n",
      " -3.63071568e-05  7.12689812e-03]\n",
      "[ 2.03210501e-02  2.54669465e-04  3.09829056e-04 ...  4.37058517e-03\n",
      " -4.43889703e-05  8.99513501e-03]\n",
      "[ 2.21118908e-02  3.04073348e-04  3.94002384e-04 ...  5.34843113e-03\n",
      " -4.57098038e-05  1.09136899e-02]\n",
      "[ 2.37604576e-02  3.47229631e-04  4.81088267e-04 ...  6.35355804e-03\n",
      " -4.01122633e-05  1.28606312e-02]\n",
      "[ 2.53213856e-02  3.85014515e-04  5.70078621e-04 ...  7.37709888e-03\n",
      " -2.83764982e-05  1.48239282e-02]\n",
      "[ 2.68268348e-02  4.18429933e-04  6.60258889e-04 ...  8.41335263e-03\n",
      " -1.14928284e-05  1.67970509e-02]\n",
      "[2.82959485e-02 4.48294987e-04 7.51113734e-04 ... 9.45865307e-03\n",
      " 9.59745399e-06 1.87763854e-02]\n",
      "[2.97404365e-02 4.75223400e-04 8.42281606e-04 ... 1.05106165e-02\n",
      " 3.40707467e-05 2.07598655e-02]\n",
      "[3.11677023e-02 4.99672426e-04 9.33517750e-04 ... 1.15676621e-02\n",
      " 6.12313936e-05 2.27462659e-02]\n",
      "[3.25825867e-02 5.21991924e-04 1.02466176e-03 ... 1.26287127e-02\n",
      " 9.05041507e-05 2.47348348e-02]\n",
      "[0.03398836 0.00054246 0.00111561 ... 0.01369301 0.00012142 0.0267251 ]\n",
      "[0.03538727 0.0005613  0.0012063  ... 0.01476    0.0001536  0.02871674]\n",
      "[0.03678095 0.00057871 0.0012967  ... 0.01582925 0.00018675 0.03070954]\n",
      "[0.03817057 0.00059484 0.00138679 ... 0.01690045 0.00022063 0.03270338]\n",
      "[0.03955699 0.00060983 0.00147655 ... 0.01797331 0.00025504 0.03469813]\n",
      "[0.04094087 0.00062381 0.00156599 ... 0.01904762 0.00028986 0.03669372]\n",
      "[0.04232271 0.00063688 0.00165511 ... 0.02012318 0.00032495 0.03869009]\n",
      "[0.0437029  0.00064913 0.00174392 ... 0.02119983 0.00036024 0.04068719]\n",
      "[0.04508175 0.00066064 0.00183242 ... 0.02227742 0.00039567 0.04268497]\n",
      "[0.04645949 0.00067148 0.00192063 ... 0.02335583 0.00043118 0.04468342]\n",
      "[0.04783633 0.00068171 0.00200856 ... 0.02443494 0.00046674 0.04668249]\n",
      "[0.04921242 0.00069139 0.00209621 ... 0.02551467 0.00050232 0.04868216]\n",
      "[0.05058789 0.00070056 0.0021836  ... 0.02659492 0.00053791 0.0506824 ]\n",
      "[0.05196283 0.00070928 0.00227073 ... 0.02767562 0.0005735  0.0526832 ]\n",
      "[0.05333734 0.00071758 0.00235763 ... 0.0287567  0.00060907 0.05468452]\n",
      "[0.05471148 0.00072548 0.0024443  ... 0.02983811 0.00064463 0.05668636]\n",
      "[0.05608532 0.00073304 0.00253075 ... 0.03091979 0.00068017 0.05868869]\n",
      "[0.05745889 0.00074027 0.00261699 ... 0.0320017  0.0007157  0.06069149]\n",
      "[0.05883225 0.00074719 0.00270304 ... 0.0330838  0.00075122 0.06269475]\n",
      "[0.06020542 0.00075384 0.00278889 ... 0.03416605 0.00078672 0.06469846]\n",
      "[0.06157844 0.00076023 0.00287457 ... 0.03524843 0.00082222 0.06670259]\n",
      "[0.06295132 0.00076638 0.00296008 ... 0.0363309  0.00085772 0.06870713]\n",
      "[0.06432409 0.00077231 0.00304543 ... 0.03741345 0.00089321 0.07071206]\n",
      "[0.06569677 0.00077803 0.00313063 ... 0.03849605 0.00092871 0.07271739]\n",
      "[0.06706936 0.00078356 0.00321569 ... 0.03957869 0.00096421 0.07472308]\n",
      "[0.0684419  0.0007889  0.00330062 ... 0.04066135 0.00099972 0.07672913]\n",
      "[0.06981437 0.00079408 0.00338543 ... 0.04174402 0.00103524 0.07873552]\n",
      "[0.07118681 0.0007991  0.00347011 ... 0.04282669 0.00107078 0.08074225]\n",
      "[0.07255921 0.00080397 0.0035547  ... 0.04390934 0.00110633 0.08274929]\n",
      "[0.07393158 0.0008087  0.00363918 ... 0.04499196 0.00114189 0.08475664]\n",
      "[0.07530393 0.00081329 0.00372357 ... 0.04607455 0.00117747 0.08676429]\n",
      "[0.07667627 0.00081776 0.00380788 ... 0.04715711 0.00121307 0.08877223]\n",
      "[0.0780486  0.00082211 0.00389212 ... 0.04823962 0.00124868 0.09078044]\n",
      "[0.07942094 0.00082634 0.00397628 ... 0.04932208 0.00128431 0.09278891]\n",
      "[0.08079328 0.00083046 0.00406039 ... 0.05040448 0.00131995 0.09479763]\n",
      "[0.08216563 0.00083447 0.00414444 ... 0.05148682 0.00135561 0.0968066 ]\n",
      "[0.08353799 0.00083838 0.00422844 ... 0.0525691  0.00139128 0.0988158 ]\n",
      "[0.08491037 0.0008422  0.0043124  ... 0.05365132 0.00142696 0.10082523]\n",
      "[0.08628278 0.00084592 0.00439632 ... 0.05473346 0.00146266 0.10283486]\n",
      "[0.08765521 0.00084955 0.00448021 ... 0.05581553 0.00149836 0.10484471]\n",
      "[0.08902768 0.00085309 0.00456407 ... 0.05689752 0.00153407 0.10685474]\n",
      "[0.09040018 0.00085654 0.00464791 ... 0.05797944 0.00156978 0.10886497]\n",
      "[0.09177272 0.00085992 0.00473174 ... 0.05906128 0.00160549 0.11087537]\n",
      "[0.0931453  0.00086321 0.00481555 ... 0.06014304 0.00164121 0.11288594]\n",
      "[0.09451793 0.00086642 0.00489935 ... 0.06122472 0.00167692 0.11489667]\n",
      "[0.0958906  0.00086955 0.00498315 ... 0.06230631 0.00171263 0.11690756]\n",
      "[0.09726333 0.00087262 0.00506694 ... 0.06338782 0.00174833 0.11891859]\n",
      "[0.09863611 0.0008756  0.00515074 ... 0.06446924 0.00178403 0.12092976]\n",
      "[0.10000895 0.00087852 0.00523453 ... 0.06555058 0.00181971 0.12294107]\n",
      "[0.10138184 0.00088137 0.00531834 ... 0.06663183 0.00185539 0.12495249]\n",
      "[0.1027548  0.00088415 0.00540215 ... 0.067713   0.00189104 0.12696404]\n",
      "[0.10412782 0.00088687 0.00548597 ... 0.06879407 0.00192669 0.1289757 ]\n",
      "[0.1055009  0.00088952 0.0055698  ... 0.06987506 0.00196231 0.13098746]\n",
      "[0.10687406 0.00089211 0.00565365 ... 0.07095596 0.00199792 0.13299932]\n",
      "[0.10824728 0.00089463 0.00573751 ... 0.07203677 0.00203351 0.13501128]\n",
      "[0.10962057 0.0008971  0.00582138 ... 0.0731175  0.00206907 0.13702333]\n",
      "[0.11099394 0.00089951 0.00590527 ... 0.07419813 0.00210461 0.13903546]\n",
      "[0.11236738 0.00090186 0.00598918 ... 0.07527867 0.00214012 0.14104766]\n",
      "[0.11374089 0.00090416 0.0060731  ... 0.07635913 0.00217561 0.14305994]\n",
      "[0.11511449 0.00090641 0.00615704 ... 0.0774395  0.00221106 0.14507229]\n",
      "[0.11648816 0.0009086  0.006241   ... 0.07851978 0.00224649 0.1470847 ]\n",
      "[0.11786191 0.00091074 0.00632497 ... 0.07959997 0.00228189 0.14909717]\n",
      "[0.11923574 0.00091283 0.00640896 ... 0.08068007 0.00231726 0.1511097 ]\n",
      "[0.12060965 0.00091488 0.00649297 ... 0.08176009 0.00235259 0.15312227]\n",
      "[0.12198364 0.00091687 0.00657699 ... 0.08284001 0.00238789 0.1551349 ]\n",
      "[0.12335771 0.00091883 0.00666103 ... 0.08391985 0.00242316 0.15714756]\n",
      "[0.12473187 0.00092073 0.00674509 ... 0.08499961 0.0024584  0.15916027]\n",
      "[0.12610611 0.0009226  0.00682916 ... 0.08607928 0.0024936  0.16117301]\n",
      "[0.12748044 0.00092442 0.00691324 ... 0.08715886 0.00252876 0.16318579]\n",
      "[0.12885485 0.0009262  0.00699734 ... 0.08823836 0.00256389 0.1651986 ]\n",
      "[0.13022935 0.00092794 0.00708145 ... 0.08931777 0.00259898 0.16721143]\n",
      "[0.13160393 0.00092964 0.00716557 ... 0.0903971  0.00263403 0.16922428]\n",
      "[0.1329786  0.00093131 0.00724971 ... 0.09147635 0.00266905 0.17123716]\n",
      "[0.13435335 0.00093293 0.00733386 ... 0.09255551 0.00270402 0.17325006]\n",
      "[0.13572819 0.00093453 0.00741802 ... 0.09363459 0.00273897 0.17526297]\n",
      "[0.13710311 0.00093608 0.00750218 ... 0.09471359 0.00277387 0.17727589]\n",
      "[0.13847812 0.0009376  0.00758636 ... 0.09579251 0.00280873 0.17928883]\n",
      "[0.13985322 0.00093909 0.00767054 ... 0.09687135 0.00284356 0.18130177]\n",
      "[0.1412284  0.00094055 0.00775474 ... 0.09795011 0.00287835 0.18331472]\n",
      "[0.14260367 0.00094197 0.00783893 ... 0.09902879 0.0029131  0.18532768]\n",
      "[0.14397903 0.00094336 0.00792314 ... 0.10010739 0.00294782 0.18734064]\n",
      "[0.14535447 0.00094471 0.00800735 ... 0.10118592 0.00298249 0.1893536 ]\n",
      "[0.14672999 0.00094604 0.00809157 ... 0.10226437 0.00301713 0.19136656]\n",
      "[0.1481056  0.00094734 0.00817578 ... 0.10334275 0.00305173 0.19337951]\n",
      "[0.1494813  0.0009486  0.00826001 ... 0.10442105 0.00308629 0.19539247]\n",
      "[0.15085707 0.00094984 0.00834423 ... 0.10549928 0.00312082 0.19740541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\okosa\\pycharmprojects\\machinelearningassignments\\venv\\lib\\site-packages\\ipykernel_launcher.py:31: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(train_x, train_y, valid_x, valid_y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Oscar Kosar-Kosarewicz"
   },
   {
    "name": "Nicholas Phillips"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}