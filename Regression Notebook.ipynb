{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Assignment\n",
    "In this problem we use the abalone dataset available on Canvas.\n",
    "The dataset is about predicting the age of the abalone from its\n",
    "physical measurements. Use the first 7 variables as predictors\n",
    "and the 8-th as the response. Report all results as the average\n",
    "of 10 random splits with 80% of data for training and 20% for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "abalone_dataset = np.loadtxt(\"data/abalone.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\" Get randomly split training and test data\n",
    "\n",
    "    :returns training_x, training_y, test_x, test_y\n",
    "    :rtype tuple(ndarray, ndarray, ndarray, ndarray)\n",
    "    \"\"\"\n",
    "    # randomly split the data into training and testing\n",
    "    training, test = train_test_split(abalone_dataset, train_size=.8, test_size=.2)\n",
    "\n",
    "    # Separate the predictor (x) and response (y) variables\n",
    "    training_x, training_y = np.hsplit(training, [7])\n",
    "    test_x, test_y = np.hsplit(test, [7])\n",
    "\n",
    "    return training_x, training_y, test_x, test_y\n",
    "\n",
    "def average_ten_runs(func):\n",
    "    \"\"\"This decorator augments your function to run ten times\n",
    "    and return the average result(s)\n",
    "\n",
    "    Example usage\n",
    "    The following function returns the average of ten random numbers:\n",
    "    @average_ten_runs\n",
    "    def random_number():\n",
    "        return random.random()\n",
    "\n",
    "    :parameter func your function\n",
    "    :returns modified version of your function that returns the mean of ten runs\n",
    "    \"\"\"\n",
    "    def wrapper(*args):\n",
    "        # Runs func 10 times, putting each returned value into a separate list\n",
    "        results = zip(*[func(*args) for __ in range(10)])\n",
    "        # finds the average of each list\n",
    "        averaged_results = tuple(sum(value_list)/10 for value_list in results)\n",
    "        return averaged_results\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## OLS Regression\n",
    "OLS regression, analytic, by solving the normal equations, with Î» = 0.0001.\n",
    "Report the average training and test R2 (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 on training data: 0.5319\n",
      "Average R2 on testing data: 0.4923\n"
     ]
    }
   ],
   "source": [
    "@average_ten_runs\n",
    "def OLS_regression():\n",
    "    \"\"\"Solves OLS regression model analytically\n",
    "\n",
    "    :returns training_R2, testing_R2 r-squared of the model predictions\n",
    "                                     on the training and testing data\n",
    "    \"\"\"\n",
    "    # get data\n",
    "    training_x, training_y, test_x, test_y = get_data()\n",
    "    # add columns of 1s\n",
    "    training_x = np.hstack((np.ones([np.size(training_x, axis=0), 1]), training_x))\n",
    "    test_x = np.hstack((np.ones([np.size(test_x, axis=0), 1]), test_x))\n",
    "\n",
    "    # Solve OLS regression model analytically using the normal equation from the lecture\n",
    "    X = training_x\n",
    "    Y = training_y\n",
    "    lmb = 0.0001\n",
    "    parameters = inv(X.T.dot(X) + lmb * np.eye(np.size(X, axis=1))).dot(X.T).dot(Y)\n",
    "\n",
    "    # predict y values\n",
    "    predicted_training_y = training_x.dot(parameters)\n",
    "    predicted_test_y = test_x.dot(parameters)\n",
    "\n",
    "    # calculate r-squared\n",
    "    training_R2 = r2_score(training_y, predicted_training_y)\n",
    "    testing_R2 = r2_score(test_y, predicted_test_y)\n",
    "\n",
    "    return training_R2, testing_R2\n",
    "\n",
    "print(\"Average R2 on training data: {:.4f}\\n\" \\\n",
    "      \"Average R2 on testing data: {:.4f}\".format(*OLS_regression()))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression Tree\n",
    "Regression trees with max depth 7 giving the r2 score for both trainign and test\n",
    "then plotted with R^2 vs tree depth(2 points)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@average_ten_runs\n",
    "def Reg_Tree(x):\n",
    "\n",
    "    training_x, training_y, test_x, test_y = get_data()\n",
    "\n",
    "    tree=DecisionTreeRegressor(max_depth=x)\n",
    "    tree.fit(training_x, training_y)\n",
    "    predicted_training_y=tree.predict(training_x)\n",
    "    predicted_test_y =tree.predict(test_x)\n",
    "    r2_tree_test=r2_score(predicted_test_y, test_y)\n",
    "    r2_tree_training=r2_score(training_y, predicted_training_y)\n",
    "\n",
    "    return r2_tree_test, r2_tree_training\n",
    "\n",
    "r2_test=[]\n",
    "r2_training=[]\n",
    "depth_trees=[]\n",
    "\n",
    "for x in range(1,8):\n",
    "    test , train = Reg_Tree(x)\n",
    "    depth_trees.append(x)\n",
    "    r2_test.append(test)\n",
    "    r2_training.append(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def R2_vs_depth_plot():\n",
    "    x1=depth_trees\n",
    "    x2=depth_trees\n",
    "    y1 = r2_training\n",
    "    y2 = r2_test\n",
    "    plt.xlabel(\"Depth of Trees\")\n",
    "    plt.ylabel(\"R squared\")\n",
    "    plt.plot(x1,y1)\n",
    "    plt.plot(x2,y2)\n",
    "\n",
    "\n",
    "\n",
    "    plt.grid(True, which='both')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "R2_vs_depth_plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Regression\n",
    "Random forest regression with 10, 30 and 100 trees. Report the average training and test R2 in each case. (3 points)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-44-45d2215e8b68>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;31m# get R2 for 10, 30, and 100 trees, arranging them into a 2D list for the table\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0mnum_trees\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m30\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34mf\"{x:.3f}\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_forest_regression\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mnum_trees\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;31m# display table\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-44-45d2215e8b68>\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;31m# get R2 for 10, 30, and 100 trees, arranging them into a 2D list for the table\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0mnum_trees\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m30\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34mf\"{x:.3f}\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_forest_regression\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mnum_trees\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;31m# display table\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-40-e96105309a95>\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m         \u001B[0;31m# Runs func 10 times, putting each returned value into a separate list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m         \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0m__\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m         \u001B[0;31m# finds the average of each list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0maveraged_results\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0;36m10\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mvalue_list\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-40-e96105309a95>\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m         \u001B[0;31m# Runs func 10 times, putting each returned value into a separate list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m         \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0m__\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m         \u001B[0;31m# finds the average of each list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0maveraged_results\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0;36m10\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mvalue_list\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-44-45d2215e8b68>\u001B[0m in \u001B[0;36mrandom_forest_regression\u001B[0;34m(num_trees_in_forest)\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;31m# train forest\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mforest\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRandomForestRegressor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_estimators\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_trees_in_forest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     \u001B[0mforest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraining_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraining_y\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0;31m# predict y values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RegressionAsignment/venv/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    390\u001B[0m                     \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclass_weight\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    391\u001B[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001B[0;32m--> 392\u001B[0;31m                 for i, t in enumerate(trees))\n\u001B[0m\u001B[1;32m    393\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    394\u001B[0m             \u001B[0;31m# Collect newly grown trees\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RegressionAsignment/venv/lib/python3.7/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1030\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1031\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1032\u001B[0;31m             \u001B[0;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1033\u001B[0m                 \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1034\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RegressionAsignment/venv/lib/python3.7/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    845\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    846\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 847\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    848\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RegressionAsignment/venv/lib/python3.7/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    763\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    764\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 765\u001B[0;31m             \u001B[0mjob\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    766\u001B[0m             \u001B[0;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    767\u001B[0m             \u001B[0;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RegressionAsignment/venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    207\u001B[0m         \u001B[0;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 208\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    209\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RegressionAsignment/venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    570\u001B[0m         \u001B[0;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    571\u001B[0m         \u001B[0;31m# arguments in memory\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 572\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    573\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    574\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RegressionAsignment/venv/lib/python3.7/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    251\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    252\u001B[0m             return [func(*args, **kwargs)\n\u001B[0;32m--> 253\u001B[0;31m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[1;32m    254\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    255\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RegressionAsignment/venv/lib/python3.7/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    251\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    252\u001B[0m             return [func(*args, **kwargs)\n\u001B[0;32m--> 253\u001B[0;31m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[1;32m    254\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    255\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RegressionAsignment/venv/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001B[0m in \u001B[0;36m_parallel_build_trees\u001B[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001B[0m\n\u001B[1;32m    166\u001B[0m                                                         indices=indices)\n\u001B[1;32m    167\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 168\u001B[0;31m         \u001B[0mtree\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcurr_sample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    169\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    170\u001B[0m         \u001B[0mtree\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RegressionAsignment/venv/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[1;32m   1244\u001B[0m             \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1245\u001B[0m             \u001B[0mcheck_input\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcheck_input\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1246\u001B[0;31m             X_idx_sorted=X_idx_sorted)\n\u001B[0m\u001B[1;32m   1247\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1248\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RegressionAsignment/venv/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[1;32m    373\u001B[0m                                            min_impurity_split)\n\u001B[1;32m    374\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 375\u001B[0;31m         \u001B[0mbuilder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtree_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_idx_sorted\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    376\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    377\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_outputs_\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mis_classifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "@average_ten_runs\n",
    "def random_forest_regression(num_trees_in_forest):\n",
    "    # get data\n",
    "    training_x, training_y, test_x, test_y = get_data()\n",
    "\n",
    "    # train forest\n",
    "    forest = RandomForestRegressor(n_estimators=num_trees_in_forest)\n",
    "    forest.fit(training_x, np.ravel(training_y))\n",
    "\n",
    "    # predict y values\n",
    "    predicted_training_y = forest.predict(training_x)\n",
    "    predicted_test_y = forest.predict(test_x)\n",
    "\n",
    "    # calculate r-squared\n",
    "    r2_test = r2_score(predicted_test_y, test_y)\n",
    "    r2_training = r2_score(training_y, predicted_training_y)\n",
    "\n",
    "    return r2_training, r2_test\n",
    "\n",
    "# get R2 for 10, 30, and 100 trees, arranging them into a 2D list for the table\n",
    "num_trees = [10, 30, 100]\n",
    "results = [[n, *map(lambda x: f\"{x:.3f}\", random_forest_regression(n))] for n in num_trees]\n",
    "\n",
    "# display table\n",
    "print(\"Average results over ten runs:\")\n",
    "plt.figure(figsize=(6, 1)) # set figure size\n",
    "plt.axis(\"off\")            # turn off plot\n",
    "plt.table(cellText=results, colLabels=[\"Number of trees\", \"Training R2\", \"Testing R2\"], loc=\"upper center\")\n",
    "plt.show()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Oscar Kosar-Kosarewicz"
   },
   {
    "name": "Nick"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}