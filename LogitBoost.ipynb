{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Logitboost Assignment\n",
    "Implement Logitboost using 1D linear regressors as weak learners. At each boosting\n",
    "iteration choose the weak learner that obtains the largest reduction in the loss function\n",
    "on the training set $D = {(x_i, y_i), i = 1, ..., N}, \\text{ with } y_i âˆˆ {0, 1}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_gisette():\n",
    "    path = \"data/gisette/\"   \n",
    "    \n",
    "    train_x = np.loadtxt(path+\"gisette_train.data\")\n",
    "    train_y = np.loadtxt(path+\"gisette_train.labels\")\n",
    "    \n",
    "    valid_x = np.loadtxt(path+\"gisette_valid.data\")\n",
    "    valid_y = np.loadtxt(path+\"gisette_valid.labels\")\n",
    "    \n",
    "    test_x = np.loadtxt(path+\"gisette_test.data\")\n",
    "\n",
    "    return train_x, train_y, valid_x, valid_y, test_x\n",
    "\n",
    "\n",
    "\n",
    "def get_dexter():\n",
    "    path = \"data/dexter/\"\n",
    "\n",
    "    train_x = np.loadtxt(path+\"dexter_train.csv\", delimiter=',')\n",
    "    train_y = np.loadtxt(path+\"dexter_train.labels\")\n",
    "\n",
    "    valid_x = np.loadtxt(path+\"dexter_valid.csv\", delimiter=',')\n",
    "    valid_y = np.loadtxt(path+\"dexter_valid.labels\")\n",
    "\n",
    "    return train_x, train_y, valid_x, valid_y\n",
    "\n",
    "def get_madelon():\n",
    "    path = \"data/MADELON/\"\n",
    "\n",
    "    train_x = np.loadtxt(path + \"madelon_train.data\")\n",
    "    train_y = np.loadtxt(path + \"madelon_train.labels\")\n",
    "    test_x = np.loadtxt(path + \"madelon_valid.data\")\n",
    "    test_y = np.loadtxt(path + \"madelon_valid.labels\")\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Normalization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(train, *args):\n",
    "    mean = np.average(train, axis=0)\n",
    "    standard_deviation = np.std(train, axis=0)\n",
    "    columns = train, *args\n",
    "    return tuple(np.divide(column-mean, standard_deviation, where=standard_deviation!=0)\n",
    "                 for column in columns)\n",
    "\n",
    "def hofx(train_x, train_y):\n",
    "    h=0\n",
    "\n",
    "    p=1/(1+np.exp(-h)) # h doesn't make sense\n",
    "    w_i=(p)*(1-p)\n",
    "    #mean_x = np.average(train_x, axis=0)\n",
    "    #mean_y = np.average(train_y, axis=0)\n",
    "    #beta_1= np.sum(w_i*(train_y-mean_y)*(train_x*mean_x))\n",
    "    #beta_1 /=(np.sum(w_i*np.square(train_x-mean_x)))\n",
    "    #beta_0= mean_y + beta_1 * mean_x\n",
    "    beta_0, beta_1 = linear_regressor_for_each_feature(train_x, train_y, w_i)\n",
    "\n",
    "\n",
    "def beta_selection(x, beta0, beta1, y):\n",
    "    h_xi= x.T * beta1 + beta0\n",
    "    ytilde=2*y-1\n",
    "    loss=np.sum(np.ln(1+np.exp(-ytilde*h_xi)), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def h()\n",
    "# I separated linear regression to its own function and transposed to vectors so they\n",
    "# broadcast correctly\n",
    "def linear_regressor_for_each_feature(x, y, w):\n",
    "    mean_x = np.average(x, axis=1)[np.newaxis] # add an axis so we can tranpose this\n",
    "    mean_y = np.average(y)\n",
    "    beta_1= np.sum(w*(y-mean_y)[np.newaxis].T*(x-mean_x.T), axis=1) /(np.sum(w*np.square(x-mean_x.T), axis=1))\n",
    "    beta_0= mean_y + beta_1 * mean_x\n",
    "    beta_0 = np.ravel(beta_0) # remove extra axis\n",
    "    return beta_0, beta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = get_dexter()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([-3.51599140e-19,  1.02433401e-18,  1.76554219e-19, -3.08411675e-19,\n        -7.42227191e-19,  2.11918050e-19, -3.33559739e-19,  6.79842884e-19,\n         7.21325689e-19, -2.64384000e-19, -3.62693350e-19, -1.57049555e-19,\n         1.99033377e-19, -1.19225897e-18,  1.08690497e-18, -2.36332291e-19,\n         1.43584607e-18,  5.39691024e-19, -3.54418658e-19,  5.80869193e-19,\n        -9.18237070e-19,  4.14323738e-19, -2.01680862e-19, -8.77342080e-19,\n        -4.73846510e-19, -5.88507893e-19, -6.19230684e-19, -1.65439232e-19,\n        -4.14983261e-19, -4.46487952e-19,  5.14764899e-19, -2.36661229e-19,\n        -2.59508034e-19, -2.73579505e-19, -1.27011311e-18,  3.91194366e-19,\n        -2.67816915e-19, -1.16874428e-18, -4.74069236e-19,  2.18401385e-18,\n        -6.41593582e-19, -7.30968979e-19, -7.98537667e-19, -9.77616664e-19,\n        -4.53719212e-19,  7.43631644e-19,  4.46661762e-19, -1.46355823e-18,\n         4.34365726e-19,  5.46992896e-19, -1.28629766e-18,  4.63258915e-19,\n         8.49771331e-20, -2.65992938e-19, -6.17076567e-19, -8.47436217e-19,\n         2.48725597e-19, -2.08963893e-19, -2.10029466e-19,  3.73210061e-19,\n         8.33800316e-19, -5.84117752e-20,  8.78386994e-20,  5.97183271e-19,\n        -2.69674160e-19,  3.04431080e-19, -6.15253598e-19, -3.02860611e-19,\n         6.29530076e-19, -1.40278133e-19, -8.08097826e-19, -5.67506106e-19,\n        -2.98662371e-20, -2.09013674e-19, -7.66888233e-19,  1.72623246e-19,\n         7.15377747e-19,  7.67149431e-19, -3.31187048e-19, -5.85004903e-19,\n        -1.05400537e-18, -1.97904521e-20,  2.28098382e-19, -8.64853745e-19,\n        -8.76952010e-20,  5.27190390e-19,  2.52858949e-19,  3.83813384e-19,\n         3.75374950e-19,  7.08776731e-20,  3.03337881e-20,  1.20870367e-19,\n         6.07949639e-19, -2.85493793e-19,  3.96572208e-19,  1.59752737e-18,\n         9.51009151e-19, -3.61838992e-19,  4.83534152e-20, -2.45593518e-19,\n         1.45043768e-18,  4.58570954e-19,  8.52627522e-20, -1.35412114e-19,\n         1.72148860e-19, -3.82971560e-19, -3.68508358e-19,  4.30700348e-19,\n        -1.27378732e-18,  1.06606843e-18, -2.53391742e-19,  6.73817210e-19,\n        -4.82016255e-19,  3.19462182e-19,  5.12547865e-19,  1.57267019e-19,\n         1.48420457e-18,  1.06397847e-19,  7.02163967e-19, -4.58765981e-19,\n         2.47136227e-19, -1.10859953e-18, -1.05279729e-18, -8.35898242e-19,\n         7.41069399e-19, -2.68497802e-19, -1.06451701e-18,  0.00000000e+00,\n        -3.88959066e-19, -2.88674039e-19,  4.96120501e-19, -6.40244817e-20,\n         7.67637643e-19,  1.35176974e-18,  5.03275462e-20,  8.35383494e-20,\n         0.00000000e+00,  4.24649528e-19,  0.00000000e+00, -4.33250185e-19,\n        -1.34929542e-18,  9.29455693e-19,  1.83629314e-19,  1.37064531e-18,\n        -5.15750268e-19,  4.70855844e-19, -3.54288554e-19, -1.18348542e-18,\n         1.79175963e-19, -4.13892733e-20, -2.53060070e-19,  2.26203978e-19,\n         5.93521599e-19,  7.67309341e-19, -2.23709661e-19, -7.05894261e-19,\n         1.82314461e-19, -5.07573233e-19,  1.92493728e-19,  1.54306960e-19,\n        -3.23838066e-19, -2.66954703e-19,  1.03935668e-18, -2.25846949e-19,\n        -3.08983974e-19,  1.03530829e-19,  5.64366798e-19, -2.00826778e-19,\n         2.50450426e-20, -2.17188367e-19,  4.95067995e-19,  2.11486916e-19,\n         4.23059725e-19, -1.18236700e-18, -6.36279908e-19, -1.63222283e-19,\n         1.61114341e-20, -1.84056913e-19, -7.96543524e-19, -3.63947721e-19,\n         5.17421045e-20,  4.73020652e-19, -4.51204811e-19, -1.48071215e-19,\n         3.92405740e-19,  6.07242870e-19,  2.73830463e-19, -2.83828915e-19,\n         6.29296259e-20,  1.48496594e-18,  0.00000000e+00, -2.97271031e-19,\n         6.15865385e-19, -2.86006475e-20,  5.43036101e-19,  0.00000000e+00,\n         7.35371821e-19,  5.70380712e-19,  6.31796856e-19, -1.76672561e-19,\n         7.15102511e-19,  1.76355543e-19, -3.82302356e-19,  9.61567406e-19,\n        -1.19114502e-19, -1.14170696e-18, -1.17900407e-18,  9.32672418e-19,\n         4.91786282e-19, -5.58355211e-19,  4.67182712e-19, -7.84866745e-19,\n        -7.51081414e-19, -1.08384678e-18,  5.02384302e-19,  1.10782810e-18,\n        -2.84983941e-19,  6.00713251e-19, -1.00230593e-18, -7.38286057e-20,\n        -1.10303274e-19,  2.75865345e-18,  3.87017191e-19, -1.20958886e-19,\n         5.57641141e-19,  1.15598124e-18, -4.20611097e-19,  1.91946747e-18,\n        -4.93010862e-20, -9.11251980e-19, -1.36504226e-18,  5.39902510e-19,\n        -1.43154546e-18,  7.27981761e-19,  6.85116593e-19,  6.98740376e-19,\n         8.98385093e-19, -8.32782678e-19, -3.46976153e-19,  5.77241381e-20,\n         3.36484055e-19,  3.93757344e-20, -5.87386608e-19,  2.56288827e-20,\n         7.83244419e-19, -5.27559478e-20,  3.91832158e-19, -3.14508155e-19,\n        -1.01969512e-18, -2.83856803e-20,  4.83870754e-19,  3.01859765e-19,\n         3.71845953e-19, -4.95900990e-19,  3.64167331e-19, -5.29738227e-19,\n        -8.80975938e-20, -3.82771241e-19, -3.31608317e-19,  4.71744808e-19,\n         7.51292268e-19,  4.28346930e-19,  1.16195013e-18, -8.76942197e-19,\n         3.71391683e-19, -6.72557326e-19,  6.96500088e-19, -1.31352746e-18,\n        -2.14817575e-19,  6.84303148e-19,  4.63123865e-19,  6.47722293e-19,\n        -2.78740194e-20,  1.28077795e-19, -5.92369660e-19,  5.26118913e-19,\n         0.00000000e+00,  4.12417433e-19,  2.45354476e-18,  2.73168493e-19,\n        -6.86251393e-20, -1.49208972e-18, -6.68900976e-20,  6.23086692e-19,\n        -6.90372839e-19,  4.60951461e-19,  5.49235481e-19,  1.67299625e-18,\n        -5.65175369e-19, -9.64374922e-20,  1.19595209e-18,  9.59111225e-19,\n         6.55553502e-19,  1.00186527e-19,  1.14899609e-19, -6.79382208e-19,\n         9.08408555e-19,  2.55706323e-19, -1.10990826e-18, -2.46776198e-19]),\n array([-8.14546833e-19,  2.31566409e-18,  5.19582751e-19, -5.65374289e-19,\n        -1.29488345e-18,  4.66882683e-19, -8.75255154e-19,  1.30525657e-18,\n         1.68062835e-18, -4.75254359e-19, -9.97643654e-19, -3.82720982e-19,\n         3.97470547e-19, -2.87083788e-18,  2.02932220e-18, -5.67833472e-19,\n         2.84410433e-18,  1.06207030e-18, -6.48524535e-19,  1.50231267e-18,\n        -2.07043308e-18,  1.04049156e-18, -4.81625939e-19, -2.11102522e-18,\n        -1.14193640e-18, -1.28523235e-18, -1.49644921e-18, -4.70265015e-19,\n        -9.47450368e-19, -9.28056437e-19,  1.35002596e-18, -4.69054066e-19,\n        -7.01847287e-19, -5.23647248e-19, -2.64579338e-18,  1.00862283e-18,\n        -7.34449239e-19, -2.55742730e-18, -1.16093850e-18,  4.33680273e-18,\n        -1.40040070e-18, -1.92918706e-18, -1.76005657e-18, -2.21958602e-18,\n        -1.19604379e-18,  1.75075137e-18,  1.15835519e-18, -2.14992028e-18,\n         1.25069313e-18,  1.29481097e-18, -2.56209074e-18,  1.00631892e-18,\n         1.63811341e-19, -4.74182972e-19, -1.51877078e-18, -1.56889053e-18,\n         5.46169514e-19, -4.30720175e-19, -6.13314252e-19,  9.58054321e-19,\n         1.45922351e-18, -1.34449937e-19,  2.16671681e-19,  1.25485033e-18,\n        -5.02514040e-19,  5.89525716e-19, -1.21965229e-18, -6.60114670e-19,\n         1.40332161e-18, -1.71531100e-19, -1.31088949e-18, -1.23761009e-18,\n        -6.79086791e-20, -5.61940244e-19, -1.76113959e-18,  5.74357830e-19,\n         1.45816907e-18,  1.98281063e-18, -8.88019970e-19, -1.13120933e-18,\n        -2.02265471e-18, -3.41008909e-20,  5.29722205e-19, -1.82055309e-18,\n        -2.16291037e-19,  1.29865843e-18,  6.21198744e-19,  9.35559742e-19,\n         7.84154899e-19,  1.27294672e-19,  7.71067313e-20,  3.18793004e-19,\n         1.36449251e-18, -7.14627768e-19,  1.05177618e-18,  2.25894707e-18,\n         1.80834598e-18, -8.68239933e-19,  1.16584485e-19, -5.17638356e-19,\n         1.97003420e-18,  9.97760997e-19,  2.27458322e-19, -3.25275315e-19,\n         4.99851509e-19, -7.75481543e-19, -7.97291990e-19,  7.62976701e-19,\n        -2.63342427e-18,  1.30469762e-18, -4.85890205e-19,  1.42020700e-18,\n        -1.27940612e-18,  6.01453792e-19,  1.37320259e-18,  3.29113778e-19,\n         2.77265939e-18,  2.69532229e-19,  1.76069199e-18, -1.02551913e-18,\n         5.53930802e-19, -1.88713853e-18, -1.49534449e-18, -1.35444907e-18,\n         1.53557687e-18, -4.70018034e-19, -3.02720604e-18,  0.00000000e+00,\n        -7.23375612e-19, -7.79252365e-19,  9.26548700e-19, -1.25452105e-19,\n         1.49447609e-18,  2.94727949e-18,  1.08945873e-19,  2.20069414e-19,\n         0.00000000e+00,  1.24003366e-18,  0.00000000e+00, -9.82538123e-19,\n        -2.63920865e-18,  1.46729133e-18,  3.80697240e-19,  3.35901314e-18,\n        -1.20685684e-18,  7.46383204e-19, -7.38562756e-19, -2.62559161e-18,\n         3.55613701e-19, -9.59973869e-20, -6.08025157e-19,  5.63116698e-19,\n         1.43640271e-18,  1.27938198e-18, -3.60880241e-19, -1.73737204e-18,\n         3.24634011e-19, -1.26498002e-18,  4.75117186e-19,  3.51216479e-19,\n        -7.91586572e-19, -5.60417137e-19,  2.29869883e-18, -5.28235175e-19,\n        -5.86307352e-19,  2.03480403e-19,  9.99498447e-19, -4.73871585e-19,\n         7.34997580e-20, -3.98072520e-19,  9.13241090e-19,  4.84284212e-19,\n         9.64348587e-19, -2.92339474e-18, -1.02774981e-18, -4.37769298e-19,\n         3.67966977e-20, -4.26600794e-19, -1.58848046e-18, -9.12149678e-19,\n         1.08759022e-19,  1.03835068e-18, -6.33714622e-19, -4.14939652e-19,\n         1.05357965e-18,  1.46500089e-18,  7.79366623e-19, -6.75541865e-19,\n         1.82934959e-19,  3.03767197e-18,  0.00000000e+00, -7.73136622e-19,\n         1.52801237e-18, -6.96896869e-20,  1.26052948e-18,  0.00000000e+00,\n         1.60194275e-18,  7.98740669e-19,  1.32911929e-18, -3.43353534e-19,\n         1.24799740e-18,  3.95904239e-19, -1.01784440e-18,  1.99371223e-18,\n        -2.83876316e-19, -2.63399921e-18, -2.72633616e-18,  2.01855301e-18,\n         1.27306829e-18, -1.16408884e-18,  9.69661087e-19, -1.50776437e-18,\n        -1.15604343e-18, -2.01645912e-18,  1.32590209e-18,  2.34908417e-18,\n        -6.06929913e-19,  1.33774246e-18, -2.49827001e-18, -1.65869705e-19,\n        -2.07805716e-19,  4.43157181e-18,  9.98882930e-19, -3.23333029e-19,\n         1.55570133e-18,  2.37856223e-18, -8.97495140e-19,  3.98312404e-18,\n        -1.54573087e-19, -2.07811170e-18, -2.67812883e-18,  9.75433622e-19,\n        -2.41876398e-18,  1.50456084e-18,  1.69541349e-18,  1.51308007e-18,\n         1.14546104e-18, -1.83391913e-18, -7.42115608e-19,  1.13619010e-19,\n         9.56328137e-19,  1.08175095e-19, -1.37448604e-18,  6.36189219e-20,\n         1.30442904e-18, -1.46503604e-19,  8.22571971e-19, -5.90293085e-19,\n        -2.01779978e-18, -5.75191091e-20,  1.27855927e-18,  6.92338911e-19,\n         8.86297112e-19, -1.37235641e-18,  7.09877838e-19, -9.46721878e-19,\n        -2.17042606e-19, -7.78623355e-19, -7.41687133e-19,  8.65825105e-19,\n         1.42411576e-18,  8.57036674e-19,  2.60468533e-18, -2.21115027e-18,\n         7.76401553e-19, -1.41249045e-18,  1.11359835e-18, -2.99311258e-18,\n        -3.95066804e-19,  1.74455869e-18,  7.66190528e-19,  1.93638951e-18,\n        -3.53372457e-20,  1.88197480e-19, -1.47117760e-18,  1.32858311e-18,\n         0.00000000e+00,  8.67151877e-19,  4.38995305e-18,  6.75156927e-19,\n        -1.83538752e-19, -2.75014233e-18, -1.38574886e-19,  8.90187430e-19,\n        -1.23900366e-18,  1.30414899e-18,  1.09935044e-18,  3.28715247e-18,\n        -1.22200080e-18, -1.90512628e-19,  2.92301623e-18,  1.70221178e-18,\n         1.49789444e-18,  2.31484582e-19,  2.42225381e-19, -1.47195799e-18,\n         1.88779833e-18,  5.99054288e-19, -2.74559867e-18, -4.15343261e-19]))"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function\n",
    "linear_regressor_for_each_feature(train_x, train_y, np.ones(train_x.shape[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Find k for 10, 30, 100, 300, 500 features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot the error vs iteration and display final error in a table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## a) Gisette\n",
    "\n",
    "Using the Gisette data, train a FSA classifier on the training set, starting with Î²(0) = 0 to select k âˆˆ {10, 30, 100, 300, 500} features. Plot the training loss vs iteration number for k = 30. Report in a table the misclassification errors on the training and test set for the models obtained for all these k. Plot the misclassification error on the training and test set vs k."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "#train_x, train_y, test_x, test_y, _ = get_gisette()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "#calibrate_k(train_x, train_y, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "#plot_fsa(train_x, train_y, test_x, test_y, [10, 30, 100, 300, 500]);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## b) Dexter\n",
    "Repeat point a) on the dexter dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "#train_x, train_y, test_x, test_y = get_dexter()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "#linear_regressor_for_each_feature(train_x, train_y, np.ones(train_x.shape[1]))\n",
    "#calibrate_k(train_x, train_y, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "#plot_fsa(train_x, train_y, test_x, test_y, [10, 30, 100, 300, 500]);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## c) Madelon\n",
    "Repeat point a) on the madelon dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "#train_x, train_y, test_x, test_y = get_madelon()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#calibrate_k(train_x, train_y, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "#plot_fsa(train_x, train_y, test_x, test_y, [10, 30, 100, 300, 500]);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Oscar Kosar-Kosarewicz"
   },
   {
    "name": "Nicholas Phillips"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}