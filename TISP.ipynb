{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TISP Assignment\n",
    "Implement the TISP variable selection method for classification (as described in\n",
    "pages 12 of the Regularized Loss course notes), with the hard-thresholding penalty,\n",
    "described in page 11 (with η = 0). Take special care to normalize each column of\n",
    "the X matrix to have zero mean and variance 1 and to use the same mean and standard\n",
    "deviation that you used for normalizing the train set also for normalizing the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_gisette():\n",
    "    path = \"data/gisette/\"   \n",
    "    \n",
    "    train_x = np.loadtxt(path+\"gisette_train.data\")\n",
    "    train_y = np.loadtxt(path+\"gisette_train.labels\")\n",
    "    \n",
    "    valid_x = np.loadtxt(path+\"gisette_valid.data\")\n",
    "    valid_y = np.loadtxt(path+\"gisette_valid.labels\")\n",
    "    \n",
    "    test_x = np.loadtxt(path+\"gisette_test.data\")\n",
    "\n",
    "    return train_x, train_y, valid_x, valid_y, test_x\n",
    "\n",
    "\n",
    "\n",
    "def get_dexter():\n",
    "    path = \"data/dexter/\"\n",
    "\n",
    "    train_x = np.loadtxt(path+\"dexter_train.csv\", delimiter=',')\n",
    "    train_y = np.loadtxt(path+\"dexter_train.labels\")\n",
    "\n",
    "    valid_x = np.loadtxt(path+\"dexter_valid.csv\", delimiter=',')\n",
    "    valid_y = np.loadtxt(path+\"dexter_valid.labels\")\n",
    "\n",
    "    return train_x, train_y, valid_x, valid_y\n",
    "\n",
    "def get_madelon():\n",
    "    path = \"data/MADELON/\"\n",
    "\n",
    "    train_x = np.loadtxt(path + \"madelon_train.data\")\n",
    "    train_y = np.loadtxt(path + \"madelon_train.labels\")\n",
    "    test_x = np.loadtxt(path + \"madelon_valid.data\")\n",
    "    test_y = np.loadtxt(path + \"madelon_valid.labels\")\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Normalization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(train, *args):\n",
    "    mean = np.average(train, axis=0)\n",
    "    standard_deviation = np.std(train, axis=0)\n",
    "    columns = train, *args\n",
    "    return tuple(np.divide(column-mean, standard_deviation, where=standard_deviation!=0)\n",
    "                 for column in columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculate the next iteration's weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def weights(w, X, eta, y):\n",
    "    n=w+eta*X.T.dot(y-(1/(1+np.exp(np.dot(-X,w)))))\n",
    "    return n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set small weights to 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def hard_threshold(w, lmbda, eta=0):\n",
    "    w[w<=lmbda] = 0\n",
    "    return w"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train logistic regression model using TISP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train_tisp(x_train, y_train, x_test, y_test, threshold):\n",
    "    iterations = 100\n",
    "    x_train, x_test = normalize(x_train, x_test)\n",
    "    x_train = np.hstack((np.ones((x_train.shape[0], 1)), x_train))\n",
    "    x_test = np.hstack((np.ones((x_test.shape[0], 1)), x_test))\n",
    "    y_train[y_train==-1] = 0\n",
    "    y_test[y_test==-1] = 0\n",
    "    learning_rate = 1 / x_train.shape[0]\n",
    "\n",
    "    w = np.zeros(x_train.shape[1])\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_scores.append(1 - accuracy_score(y_train, predict(x_train, w)))\n",
    "    test_scores.append(1 - accuracy_score(y_test, predict(x_test, w)))\n",
    "    for _ in range(iterations):\n",
    "        w = weights(w, x_train, learning_rate, y_train)\n",
    "        w = hard_threshold(w, threshold)\n",
    "        train_scores.append(1 - accuracy_score(y_train, predict(x_train, w)))\n",
    "        test_scores.append(1 - accuracy_score(y_test, predict(x_test, w)))\n",
    "    number_of_features = np.count_nonzero(w)\n",
    "    return test_scores, train_scores, number_of_features\n",
    "\n",
    "def predict(X,w):\n",
    "    return np.round(1 /(1 + np.exp(-X @ w)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Find lamda for 10, 30, 100, 300, 500 features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def calibrate_lambda(x_train, y_train, x_test, y_test):\n",
    "    targets = [10, 30, 100, 300, 500]\n",
    "    threshold_per_target = []\n",
    "    for target in targets:\n",
    "        threshold = .1\n",
    "        increment = -.05\n",
    "        _, _, num_features = train_tisp(x_train, y_train, x_test, y_test, threshold)\n",
    "        prev_features = num_features\n",
    "        counter = 0\n",
    "        while num_features != target:\n",
    "            prev_distance = abs(prev_features - target)\n",
    "            distance = abs(num_features - target)\n",
    "            if distance > prev_distance:\n",
    "                increment /= -2\n",
    "            threshold += increment\n",
    "            prev_features = num_features\n",
    "            _, _, num_features = train_tisp(x_train, y_train, x_test, y_test, threshold)\n",
    "            counter += 1\n",
    "            if(counter > 30):\n",
    "                break\n",
    "            print(counter)\n",
    "        threshold_per_target.append((target, threshold))\n",
    "    return threshold_per_target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot the error vs iteration and display final error in a table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def plot(features, thresholds, test_errors, train_errors, train_errors_to_plot, test_errors_to_plot):\n",
    "    iteration = list(range(101))\n",
    "    plt.plot(iteration, train_errors_to_plot);\n",
    "    plt.plot(iteration, test_errors_to_plot);\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Misclassification error\")\n",
    "    plt.title(\"Error vs iterations with approximately 300 features\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(features, train_errors)\n",
    "    plt.plot(features, test_errors)\n",
    "    plt.xlabel(\"Number of features\")\n",
    "    plt.ylabel(\"Final misclassification error\")\n",
    "    plt.title(\"Features vs misclassification error\")\n",
    "\n",
    "    thresholds = [f\"{threshold:.3f}\" for threshold in thresholds]\n",
    "    test_errors = [f\"{test_error:.3f}\" for test_error in test_errors]\n",
    "    train_errors = [f\"{train_error:.3f}\" for train_error in train_errors]\n",
    "    plt.table(cellText=[*zip(features, thresholds, train_errors, test_errors)], colLabels=['Features','Threshold', 'Training error', 'Test error'],\n",
    "              bbox=[0.0,-0.8, 1,.4], edges=\"closed\" )\n",
    "    plt.show()\n",
    "\n",
    "def plot_tisp(x_train, y_train, x_test, y_test, thresholds):\n",
    "    features = []\n",
    "    train_errors = []\n",
    "    test_errors =[]\n",
    "    train_errors_to_plot = None\n",
    "    test_errors_to_plot = None\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        test_error, train_error, num_features = train_tisp(x_train, y_train, x_test, y_test, threshold)\n",
    "        features.append(num_features)\n",
    "        train_errors.append(train_error[-1])\n",
    "        test_errors.append(test_error[-1])\n",
    "        if i==3:\n",
    "            train_errors_to_plot = train_error\n",
    "            test_errors_to_plot = test_error\n",
    "    plot(features, thresholds, test_errors, train_errors, train_errors_to_plot, test_errors_to_plot)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## a) Gisette\n",
    "Using the Gisette data, train a TISP classifier on the training set, starting with\n",
    "w(0) = 0, with 100 iterations. Find appropriate λ-s to select approximately\n",
    "10, 30, 100, 300, 500 features. Plot the train misclassification error vs iteration\n",
    "number when selecting 300 features. Plot the final train and test misclassification\n",
    "error vs the number of selected features. Report in a table these misclassification\n",
    "errors on the training and test set, the corresponding numbers of selected features\n",
    "and the values of λ."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, _ = get_gisette()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#calibrate_lambda(train_x, train_y, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_tisp(train_x, train_y, test_x, test_y, [.1078, .0738, .0365, .0125, .008984]);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## b) Dexter\n",
    "Repeat point a) on the dexter dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = get_dexter()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#calibrate_lambda(train_x, train_y, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_tisp(train_x, train_y, test_x, test_y, [.1109,.08516,.05381, .04136, .03828]);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## c) Madelon\n",
    "Repeat point a) on the madelon dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = get_madelon()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#calibrate_lambda(train_x, train_y, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_tisp(train_x, train_y, test_x, test_y, [.02539, .0203, .01045, 0, 0]);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Oscar Kosar-Kosarewicz"
   },
   {
    "name": "Nicholas Phillips"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}