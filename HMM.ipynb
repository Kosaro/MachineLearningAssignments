{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HMM Assignment\n",
    "1. Download the dataset hmm_pb1.csv from Canvas. It represents a sequence of\n",
    "dice rolls $x$ from the Dishonest casino model discussed in class. The model parameters\n",
    "are exactly those presented in class. The states of $Y$ are 1=’Fair’ and 2=’Loaded’.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from os.path import join\n",
    "from scipy.stats import multivariate_normal\n",
    "from itertools import repeat\n",
    "from random import randint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data loading functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "def get_pb1():\n",
    "    return load_data(\"hmm_pb1.csv\")\n",
    "\n",
    "def get_pb2():\n",
    "    return load_data(\"hmm_pb2.csv\")\n",
    "\n",
    "def load_data(filename):\n",
    "    path = \"data/HMM/\"\n",
    "    data = np.loadtxt(join(path,filename), delimiter=',')\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Emission"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "def fair_die_emission():\n",
    "    return 1/6\n",
    "\n",
    "def loaded_die_emission(value):\n",
    "    if value == 6:\n",
    "        return .5\n",
    "    else:\n",
    "        return .1\n",
    "\n",
    "def emission(value):\n",
    "    return np.asarray((fair_die_emission(), loaded_die_emission(value)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "a) Implement the Viterbi algorithm and find the most likely sequence $y$ that generated the observed $x$.\n",
    " Use the log probabilities, as shown in the HMM slides from\n",
    "Canvas. Report the obtained sequence $y$ of 1’s and 2’s for verification. (2 points)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "def viterbi(sequence):\n",
    "    a = np.asarray([[.95,.05],[.05,.95]]) # transition probability\n",
    "    b = emission(sequence[0]) # Emission probability\n",
    "    p = np.asarray((.5,.5)) # Start probability\n",
    "    C = np.ndarray((sequence.size, 2))\n",
    "    ptr = np.ndarray((sequence.size-1, 2))\n",
    "    C[0] = np.log(b*p)\n",
    "    for i in range(1,sequence.size):\n",
    "        for k in range(2):\n",
    "            temp = np.log(a[k])+C[i-1]\n",
    "            C[i,k] = np.log(emission(sequence[i])[k]) + np.max(temp)\n",
    "            ptr[i-1, k] = np.argmax(temp)\n",
    "    predicted = np.empty_like(sequence)\n",
    "    predicted[-1] = np.argmax(C[-1])\n",
    "    for i in range(predicted.size-2, 0, -1):\n",
    "        predicted[i] = ptr[i,int(predicted[i+1])]\n",
    "    predicted = np.round(predicted)+1\n",
    "    print(predicted)\n",
    "\n",
    "\n",
    "viterbi(get_pb1())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "b) Implement the forward and backward algorithms and run them on the observed\n",
    "x. You should memorize a common factor $u_t$ for the $\\alpha_t^k$\n",
    "to avoid floating point underflow, since $\\alpha_t^k$ quickly become very small. The same holds for\n",
    "$\\beta_t^k$. Report $\\alpha_{125}^1 / \\alpha^2_{125}$ and $\\beta_{125}^1 / \\beta^2_{125}$,\n",
    "where the counting starts from $t$ = 1. (3 points)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3989127511917305\n"
     ]
    }
   ],
   "source": [
    "def forward(sequence):\n",
    "    tran = np.asarray([[.95,.05],[.05,.95]]) # transition probability\n",
    "    b = emission(sequence[0]) # Emission probability\n",
    "    p = np.asarray((.5,.5)) # Start probability\n",
    "    a = np.ndarray((sequence.size, 2))\n",
    "    a[0] = b*p\n",
    "    for i in range(1,sequence.size):\n",
    "        a[i] = emission(sequence[i]) * np.sum(a[i-1]*tran, axis=1)\n",
    "        a[i] *=6 # multiply by constant to avoid overflow\n",
    "    return a\n",
    "\n",
    "a = forward(get_pb1())\n",
    "print(a[124,0]/a[124,1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.856448201261194\n"
     ]
    }
   ],
   "source": [
    "def backward(sequence):\n",
    "    tran = np.asarray([[.95,.05],[.05,.95]]) # transition probability\n",
    "    B = np.ndarray((sequence.size, 2))\n",
    "    B[-1] = np.ones(2)\n",
    "    for i in range(sequence.size-2, -1, -1):\n",
    "        B[i] = np.sum(tran*B[i+1]*emission(sequence[i+1]), axis=1)\n",
    "        B[i] *=6 # multiply by constant to avoid overflow\n",
    "    return B\n",
    "\n",
    "B = backward(get_pb1())\n",
    "print(B[124,0]/B[124,1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Download the dataset hmm_pb2.csv from Canvas. It represents a sequence of\n",
    "10000 dice rolls x from the Dishonest casino model but with other values for the a and\n",
    "b parameters than those from class. Having so many observations, you are going to\n",
    "learn the model parameters.\n",
    "\n",
    "Implement and run the Baum-Welch algorithm using the forward and backward\n",
    "algorithms that you already implemented for Pb 1. You can initialize the $\\pi,a,b$ with\n",
    "your guess, or with some random probabilities (make sure that $\\pi$ sums to 1 and that\n",
    "$a_{ij}, b^i_k$\n",
    "sum to 1 for each $i$). The algorithm converges quite slowly, so you might need\n",
    "to run it for up 1000 iterations or more for the parameters to converge.\n",
    "Report the values of $\\pi,a,b$ that you have obtained. (4 points)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "1.537468961016016e-179\n",
      "0\n",
      "pi [0.71487891 0.28532109]\n",
      "a [[3.08535598e-179 3.07100243e-181]\n",
      " [7.07693692e-180 3.94238069e-179]]\n",
      "b [[0.19001447 0.00668553]\n",
      " [0.19573887 0.00626113]\n",
      " [0.18219973 0.00640027]\n",
      " [0.1890569  0.0063431 ]\n",
      " [0.1199631  0.0041369 ]\n",
      " [0.08141721 0.01178279]]\n",
      "b sum [0.95839028 0.04160972]\n"
     ]
    }
   ],
   "source": [
    "def baum_welch(sequence):\n",
    "    for _ in range(20):\n",
    "        # Expection step\n",
    "        a = np.asarray([[.95,.05],[.05,.95]]) # transition probability\n",
    "        A = forward(sequence)\n",
    "        B = backward(sequence)\n",
    "        emissions = np.asarray([emission(i) for i in range(1,7)])\n",
    "        gamma = A*B / np.sum(A*B, axis=1)[np.newaxis].T+ .0001\n",
    "        eta = np.ndarray((sequence.size,2,2))\n",
    "        for t in range(sequence.size):\n",
    "            for i in range(2):\n",
    "                for j in range(2):\n",
    "                    temp = A[t,i]*a[i,j]*B[t,j]*(emissions[int(sequence[t]-1)][j])\n",
    "                    eta[t,i,j] = temp\n",
    "\n",
    "        # maximization step\n",
    "        pi = gamma[0]\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                a[i,j] = np.sum(eta[:,i,j])/np.sum(gamma[:,i])\n",
    "        for i in range(2):\n",
    "            for k in range(1,7):\n",
    "                emissions[k-1,i] = np.sum(gamma[sequence==k, i])/np.sum(gamma)\n",
    "    print(\"pi\", pi)\n",
    "    print(\"a\", a)\n",
    "    print(\"b\",emissions)\n",
    "    print(\"b sum\",np.sum(emissions, axis=0))\n",
    "\n",
    "\n",
    "\n",
    "baum_welch(get_pb2())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Oscar Kosar-Kosarewicz"
   },
   {
    "name": "Nicholas Phillips"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}