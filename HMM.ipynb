{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HMM Assignment\n",
    "1. Download the dataset hmm_pb1.csv from Canvas. It represents a sequence of\n",
    "dice rolls $x$ from the Dishonest casino model discussed in class. The model parameters\n",
    "are exactly those presented in class. The states of $Y$ are 1=’Fair’ and 2=’Loaded’.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from os.path import join\n",
    "from scipy.stats import multivariate_normal\n",
    "from itertools import repeat\n",
    "from random import randint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data loading functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_pb1():\n",
    "    return load_data(\"hmm_pb1.csv\")\n",
    "\n",
    "def get_pb2():\n",
    "    return load_data(\"hmm_pb2.csv\")\n",
    "\n",
    "def load_data(filename):\n",
    "    path = \"data/HMM/\"\n",
    "    data = np.loadtxt(join(path,filename), delimiter=',')\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "a) Implement the Viterbi algorithm and find the most likely sequence $y$ that generated the observed $x$.\n",
    " Use the log probabilities, as shown in the HMM slides from\n",
    "Canvas. Report the obtained sequence $y$ of 1’s and 2’s for verification. (2 points)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def fair_die_emission():\n",
    "    return 1/6\n",
    "\n",
    "def loaded_die_emission(value):\n",
    "    if value == 6:\n",
    "        return .5\n",
    "    else:\n",
    "        return .1\n",
    "\n",
    "def emission(value):\n",
    "    return np.asarray((fair_die_emission(), loaded_die_emission(value)))\n",
    "\n",
    "def viterbi(sequence):\n",
    "    a = np.asarray((.95,.95)) # transition probability\n",
    "    b = emission(sequence[0]) # Emission probability\n",
    "    p = np.asarray((.5,.5)) # Start probability\n",
    "    C = np.ndarray((sequence.size, 2))\n",
    "    ptr = np.ndarray(sequence.size-1)\n",
    "    C[0] = np.log(b*p)\n",
    "    for i in range(1,sequence.size):\n",
    "        C[i] = np.log(emission(sequence[i])) + np.max(np.log(a)+C[i-1])\n",
    "        ptr[i-1] = np.argmax(np.log(a)+C[i-1])\n",
    "    predicted_probability = np.exp(np.max(C, axis=1))\n",
    "    predicted = np.empty_like(sequence)\n",
    "    predicted[-1] = np.argmax(C[-1])\n",
    "\n",
    "\n",
    "viterbi(get_pb1())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "b) Implement the forward and backward algorithms and run them on the observed\n",
    "x. You should memorize a common factor $u_t$ for the $\\alpha_t^k$\n",
    "to avoid floating point underflow, since $\\alpha_t^k$ quickly become very small. The same holds for\n",
    "$\\beta_t^k$. Report $\\alpha_{125}^1 / \\alpha^2_{125}$ and $\\beta_{125}^1 / \\beta^2_{125}$,\n",
    "where the counting starts from $t$ = 1. (3 points)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Download the dataset hmm_pb2.csv from Canvas. It represents a sequence of\n",
    "10000 dice rolls x from the Dishonest casino model but with other values for the a and\n",
    "b parameters than those from class. Having so many observations, you are going to\n",
    "learn the model parameters.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement and run the Baum-Welch algorithm using the forward and backward\n",
    "algorithms that you already implemented for Pb 1. You can initialize the $\\pi,a,b$ with\n",
    "your guess, or with some random probabilities (make sure that $\\pi$ sums to 1 and that\n",
    "$a_{ij}, b^i_k$\n",
    "sum to 1 for each $i$). The algorithm converges quite slowly, so you might need\n",
    "to run it for up 1000 iterations or more for the parameters to converge.\n",
    "Report the values of $\\pi,a,b$ that you have obtained. (4 points)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Oscar Kosar-Kosarewicz"
   },
   {
    "name": "Nicholas Phillips"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}